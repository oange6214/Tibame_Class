{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "FsWkMRcIgmuP",
    "outputId": "73134ceb-e565-482a-b5f0-e421147b11ac"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    fname=\"aclImdb.tar.gz\", \n",
    "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
    "    extract=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9fguAV-hM_w"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def read(fp):\n",
    "    with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "def read_data(base):\n",
    "    pos = glob.glob(os.path.join(base, \"pos\", \"*\"))\n",
    "    neg = glob.glob(os.path.join(base, \"neg\", \"*\"))\n",
    "    df = pd.DataFrame({\n",
    "        \"path\":(neg + pos),\n",
    "        \"target\":([0]*len(neg) + [1] * len(pos))\n",
    "    })\n",
    "    df[\"content\"] = df[\"path\"].apply(read)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "kg5B30GYj5o3",
    "outputId": "69453443-dd33-4e4e-c107-b079e2661b5c"
   },
   "outputs": [],
   "source": [
    "dirname = os.path.dirname(dataset)\n",
    "base = os.path.join(dirname, \"aclImdb\", \"train\")\n",
    "train_df = read_data(base)\n",
    "base = os.path.join(dirname, \"aclImdb\", \"test\")\n",
    "test_df = read_data(base)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8Td9t7VnfO9"
   },
   "outputs": [],
   "source": [
    "# 預處理1. 先把文字化成數字\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# 出現太少的詞, 你可以選擇不看, 只留出現次數最高的2000(num_words)\n",
    "tok = Tokenizer(num_words=2000)\n",
    "tok.fit_on_texts(train_df[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCqUAZtoo7C3"
   },
   "outputs": [],
   "source": [
    "# 想要看每個單詞被給的編號: tok.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "zmicc44_pZfs",
    "outputId": "7c12b990-4381-4d4d-b8a5-3c8bb2d688b8"
   },
   "outputs": [],
   "source": [
    "x_train_seq = tok.texts_to_sequences(train_df[\"content\"])\n",
    "x_test_seq = tok.texts_to_sequences(test_df[\"content\"])\n",
    "pd.DataFrame(x_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "Qn4wuq1sr-Bi",
    "outputId": "343914fc-bb36-4f38-ceb1-ba7a6cc74b21"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_train_pad = pad_sequences(x_train_seq, maxlen=256)\n",
    "x_test_pad = pad_sequences(x_test_seq, maxlen=256)\n",
    "pd.DataFrame(x_train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dropout, Dense\n",
    "\n",
    "layers = [\n",
    "    # 2001 * 64 = 128064\n",
    "    Embedding(2001, 64, mask_zero=True, input_length=256),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(2, activation='softmax')\n",
    "]\n",
    "\n",
    "model = Sequential(layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=3, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "model.compile(loss=SparseCategoricalCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model.fit(x_train_pad,\n",
    "         np.array(train_df['target']),\n",
    "         batch_size=200,\n",
    "         epochs=100,\n",
    "         validation_split=0.1,\n",
    "         verbose=2,\n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_pad, np.array(test_df['target']))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
